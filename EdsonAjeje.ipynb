{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Projeto de Visualização da Informação**\n",
    "\n",
    "##### **Nome**: Edson Rodrigues Ajeje\n",
    "##### **RGM**: 31995519\n",
    "##### **Instituição**: Universidade Cruzeiro do Sul\n",
    "##### **Curso**: Ciência da Computação\n",
    "\n",
    "##### **Link do dataset utilizado**:\n",
    "https://www.kaggle.com/competitions/fake-news/overview\n",
    "\n",
    "##### **Link do vídeo de apresentação**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeira Visualização\n",
    "\n",
    "**Núvem de palavras com os títulos das notícias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caso ainda não tenha instado as bibliotecas pode utilizar os comandos abaixo\n",
    "# !pip install WordCloud\n",
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install matplotlib\n",
    "# !pip install PIL\n",
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar os pacotes necessários\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar o arquivo csv em um df\n",
    "df = pd.read_csv('DataSets/train.csv', low_memory = False)\n",
    "\n",
    "# Visualizando as primeiras linhas do DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminar as colunas com valores ausentes e utilizar somente a coluna title\n",
    "titles = df.dropna(subset=['title'], axis=0)['title']\n",
    "\n",
    "# exemplos de descrições para os imóveis no Airbnb\n",
    "print(titles.iloc[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista de stopword\n",
    "nltk.download('stopwords')\n",
    "nltk_stopwords.words('english')\n",
    "\n",
    "stop_words = set(nltk_stopwords.words('english'))\n",
    "\n",
    "# concatenar as palavras\n",
    "titles_on_string = \" \".join(s for s in titles)\n",
    "\n",
    "# tokenizando o set\n",
    "tokens = word_tokenize(titles_on_string)\n",
    "\n",
    "# removendo stopwords no set\n",
    "filtered_titles = [w for w in tokens if not w.lower() in stop_words]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando a WordCloud\n",
    "wordcloud = WordCloud(stopwords=nltk_stopwords.words('english'),\n",
    "                      background_color=\"black\",\n",
    "                      width=1600, height=800).generate(titles_on_string)\n",
    "\n",
    "# Mostrar a imagem final da WordCloud\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.imshow(wordcloud, interpolation='bilinear')\n",
    "ax.set_axis_off()\n",
    "plt.imshow(wordcloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lista de 14 palavras com maior importância segundo a núvem de palavras**\n",
    "\n",
    "- York Times\n",
    "- New York\n",
    "- Breitbart\n",
    "- Trump\n",
    "- Donald Trump\n",
    "- Hillary\n",
    "- Obama\n",
    "- Clinton\n",
    "- Election\n",
    "- Russia\n",
    "- American\n",
    "- Putin\n",
    "- Video\n",
    "- Syria\n",
    "\n",
    "Após análise da lista, pode-se reduzir agrupando termos semelhantes em significado, como nomes próprios, por exemplo. A lista resultante terá 11 entradas:\n",
    "\n",
    "- (New) York Times\n",
    "- New York\n",
    "- Breitbart\n",
    "- Trump / Donald Trump\n",
    "- Hillary / Hillary Clinton\n",
    "- Obama\n",
    "- Election\n",
    "- Russia / Putin\n",
    "- American\n",
    "- Video\n",
    "- Syria\n",
    "\n",
    "Com base nessa lista, é possível fazer uma nova visualização, filtrando a base de dados original por aquelas que apresentam pelo menos uma das palavras da lista na coluna \"titles\", e a partir desse novo dataset, gerar novas visualizações."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
